{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030d1a23-ff54-4f10-96fb-3bc05a14eb7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "io.delta.exceptions.ConcurrentAppendException: [DELTA_CONCURRENT_APPEND] ConcurrentAppendException: Files were added to the root of the table by a concurrent update. Please try the operation again.\n",
       "Conflicting commit: {\"timestamp\":1747437269013,\"userId\":\"8965838320452753\",\"userName\":\"dimakamalov@asana.com\",\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":Append,\"statsOnLoad\":false,\"partitionBy\":[]},\"notebook\":{\"notebookId\":\"3432783165096853\"},\"clusterId\":\"0516-192147-rtzlk7hq\",\"readVersion\":1,\"isolationLevel\":\"Serializable\",\"isBlindAppend\":true,\"operationMetrics\":{\"numFiles\":\"1\",\"numOutputRows\":\"1\",\"numOutputBytes\":\"1123\"},\"tags\":{\"noRowsCopied\":\"true\",\"restoresDeletedRows\":\"false\"},\"engineInfo\":\"Databricks-Runtime/16.4.x-scala2.12\",\"txnId\":\"ed9e1c09-f7ac-45d9-9917-9c1115878ca5\"}\n",
       "Refer to https://docs.databricks.com/delta/concurrency-control.html for more details.\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException(DeltaErrors.scala:2675)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException$(DeltaErrors.scala:2668)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.concurrentAppendException(DeltaErrors.scala:3948)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$3(ConflictCheckerEdge.scala:626)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$1(ConflictCheckerEdge.scala:651)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictChecker.recordTime(ConflictChecker.scala:1247)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn(ConflictCheckerEdge.scala:587)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictChecker.checkConflicts(ConflictChecker.scala:471)\n",
       "\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkConflicts(ConflictCheckerEdge.scala:252)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion(OptimisticTransactionImplEdge.scala:1069)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion$(OptimisticTransactionImplEdge.scala:1051)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflictsAgainstVersion(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10(OptimisticTransaction.scala:3181)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10$adapted(OptimisticTransaction.scala:3177)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$2(OptimisticTransaction.scala:3177)\n",
       "\tat com.databricks.sql.transaction.tahoe.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:697)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$1(OptimisticTransaction.scala:3136)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts(OptimisticTransaction.scala:3136)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts$(OptimisticTransaction.scala:3126)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflicts(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$4(OptimisticTransaction.scala:2659)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$3(OptimisticTransaction.scala:2650)\n",
       "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$2(OptimisticTransaction.scala:2642)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$1(OptimisticTransaction.scala:2642)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.lockCommitIfEnabled(OptimisticTransaction.scala:2613)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.doCommitRetryIteratively(OptimisticTransaction.scala:2629)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.doCommitRetryIteratively$(OptimisticTransaction.scala:2625)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.doCommitRetryIteratively(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.liftedTree1$1(OptimisticTransactionImplEdge.scala:633)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.$anonfun$commitImpl$1(OptimisticTransactionImplEdge.scala:496)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.commitImpl(OptimisticTransactionImplEdge.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.commitImpl$(OptimisticTransactionImplEdge.scala:484)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.commitIfNeeded(OptimisticTransaction.scala:1480)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.commitIfNeeded$(OptimisticTransaction.scala:1476)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.commitIfNeeded(OptimisticTransaction.scala:196)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.performUpdate(UpdateCommandEdge.scala:347)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$4(UpdateCommandEdge.scala:183)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$4$adapted(UpdateCommandEdge.scala:177)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$3(UpdateCommandEdge.scala:177)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.withOperationTypeTag(DeltaDMLCommandEdge.scala:55)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordFrameProfile(DeltaDMLCommandEdge.scala:55)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordOperation(DeltaDMLCommandEdge.scala:55)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordDeltaOperation(DeltaDMLCommandEdge.scala:55)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$1(UpdateCommandEdge.scala:175)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2414)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2414)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.runCommand(UpdateCommandEdge.scala:168)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.runFunc$1(DeltaDMLCommandEdge.scala:72)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.$anonfun$run$1(DeltaDMLCommandEdge.scala:91)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.RunWithClonedSparkSession.runWithClonedSparkSession(DMLUtils.scala:128)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.RunWithClonedSparkSession.runWithClonedSparkSession$(DMLUtils.scala:121)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.runWithClonedSparkSession(DeltaDMLCommandEdge.scala:55)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.run(DeltaDMLCommandEdge.scala:91)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n",
       "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:432)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:432)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:431)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n",
       "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:763)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:209)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:700)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:427)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1268)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:423)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:360)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:421)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:485)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:480)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:480)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:480)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:316)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1755)\n",
       "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1816)\n",
       "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:321)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1454)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1454)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1127)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1079)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1151)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:348)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:448)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:472)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:467)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1287)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1278)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:128)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:128)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1203)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1687)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:846)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n",
       "\t\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException(DeltaErrors.scala:2675)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException$(DeltaErrors.scala:2668)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.concurrentAppendException(DeltaErrors.scala:3948)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$3(ConflictCheckerEdge.scala:626)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$1(ConflictCheckerEdge.scala:651)\n",
       "\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictChecker.recordTime(ConflictChecker.scala:1247)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn(ConflictCheckerEdge.scala:587)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictChecker.checkConflicts(ConflictChecker.scala:471)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkConflicts(ConflictCheckerEdge.scala:252)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion(OptimisticTransactionImplEdge.scala:1069)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion$(OptimisticTransactionImplEdge.scala:1051)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflictsAgainstVersion(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10(OptimisticTransaction.scala:3181)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10$adapted(OptimisticTransaction.scala:3177)\n",
       "\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$2(OptimisticTransaction.scala:3177)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:697)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$1(OptimisticTransaction.scala:3136)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\t\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\t\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\t\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\t\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\t\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\t\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\t\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\t\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts(OptimisticTransaction.scala:3136)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts$(OptimisticTransaction.scala:3126)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflicts(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$4(OptimisticTransaction.scala:2659)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n",
       "\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n",
       "\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n",
       "\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\t\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\t\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\t\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\t\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\t\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n",
       "\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n",
       "\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n",
       "\t\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\t\tat com.databricks.spark"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "ConcurrentAppendException: [DELTA_CONCURRENT_APPEND] ConcurrentAppendException: Files were added to the root of the table by a concurrent update. Please try the operation again.\nConflicting commit: {\"timestamp\":1747437269013,\"userId\":\"8965838320452753\",\"userName\":\"dimakamalov@asana.com\",\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":Append,\"statsOnLoad\":false,\"partitionBy\":[]},\"notebook\":{\"notebookId\":\"3432783165096853\"},\"clusterId\":\"0516-192147-rtzlk7hq\",\"readVersion\":1,\"isolationLevel\":\"Serializable\",\"isBlindAppend\":true,\"operationMetrics\":{\"numFiles\":\"1\",\"numOutputRows\":\"1\",\"numOutputBytes\":\"1123\"},\"tags\":{\"noRowsCopied\":\"true\",\"restoresDeletedRows\":\"false\"},\"engineInfo\":\"Databricks-Runtime/16.4.x-scala2.12\",\"txnId\":\"ed9e1c09-f7ac-45d9-9917-9c1115878ca5\"}\nRefer to https://docs.databricks.com/delta/concurrency-control.html for more details."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "DELTA_CONCURRENT_APPEND",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "2D521",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "io.delta.exceptions.ConcurrentAppendException: [DELTA_CONCURRENT_APPEND] ConcurrentAppendException: Files were added to the root of the table by a concurrent update. Please try the operation again.\nConflicting commit: {\"timestamp\":1747437269013,\"userId\":\"8965838320452753\",\"userName\":\"dimakamalov@asana.com\",\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":Append,\"statsOnLoad\":false,\"partitionBy\":[]},\"notebook\":{\"notebookId\":\"3432783165096853\"},\"clusterId\":\"0516-192147-rtzlk7hq\",\"readVersion\":1,\"isolationLevel\":\"Serializable\",\"isBlindAppend\":true,\"operationMetrics\":{\"numFiles\":\"1\",\"numOutputRows\":\"1\",\"numOutputBytes\":\"1123\"},\"tags\":{\"noRowsCopied\":\"true\",\"restoresDeletedRows\":\"false\"},\"engineInfo\":\"Databricks-Runtime/16.4.x-scala2.12\",\"txnId\":\"ed9e1c09-f7ac-45d9-9917-9c1115878ca5\"}\nRefer to https://docs.databricks.com/delta/concurrency-control.html for more details.\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException(DeltaErrors.scala:2675)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException$(DeltaErrors.scala:2668)\n\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.concurrentAppendException(DeltaErrors.scala:3948)\n\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$3(ConflictCheckerEdge.scala:626)\n\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$1(ConflictCheckerEdge.scala:651)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.sql.transaction.tahoe.ConflictChecker.recordTime(ConflictChecker.scala:1247)\n\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn(ConflictCheckerEdge.scala:587)\n\tat com.databricks.sql.transaction.tahoe.ConflictChecker.checkConflicts(ConflictChecker.scala:471)\n\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkConflicts(ConflictCheckerEdge.scala:252)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion(OptimisticTransactionImplEdge.scala:1069)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion$(OptimisticTransactionImplEdge.scala:1051)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflictsAgainstVersion(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10(OptimisticTransaction.scala:3181)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10$adapted(OptimisticTransaction.scala:3177)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$2(OptimisticTransaction.scala:3177)\n\tat com.databricks.sql.transaction.tahoe.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:697)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$1(OptimisticTransaction.scala:3136)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts(OptimisticTransaction.scala:3136)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts$(OptimisticTransaction.scala:3126)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflicts(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$4(OptimisticTransaction.scala:2659)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$3(OptimisticTransaction.scala:2650)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$2(OptimisticTransaction.scala:2642)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$1(OptimisticTransaction.scala:2642)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.lockCommitIfEnabled(OptimisticTransaction.scala:2613)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.doCommitRetryIteratively(OptimisticTransaction.scala:2629)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.doCommitRetryIteratively$(OptimisticTransaction.scala:2625)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.doCommitRetryIteratively(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.liftedTree1$1(OptimisticTransactionImplEdge.scala:633)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.$anonfun$commitImpl$1(OptimisticTransactionImplEdge.scala:496)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.commitImpl(OptimisticTransactionImplEdge.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.commitImpl$(OptimisticTransactionImplEdge.scala:484)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.commitIfNeeded(OptimisticTransaction.scala:1480)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.commitIfNeeded$(OptimisticTransaction.scala:1476)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.commitIfNeeded(OptimisticTransaction.scala:196)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.performUpdate(UpdateCommandEdge.scala:347)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$4(UpdateCommandEdge.scala:183)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$4$adapted(UpdateCommandEdge.scala:177)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:302)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$3(UpdateCommandEdge.scala:177)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.withOperationTypeTag(DeltaDMLCommandEdge.scala:55)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordFrameProfile(DeltaDMLCommandEdge.scala:55)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordOperation(DeltaDMLCommandEdge.scala:55)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.recordDeltaOperation(DeltaDMLCommandEdge.scala:55)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.$anonfun$runCommand$1(UpdateCommandEdge.scala:175)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2414)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:212)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2414)\n\tat com.databricks.sql.transaction.tahoe.commands.UpdateCommandEdge.runCommand(UpdateCommandEdge.scala:168)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.runFunc$1(DeltaDMLCommandEdge.scala:72)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.$anonfun$run$1(DeltaDMLCommandEdge.scala:91)\n\tat com.databricks.sql.transaction.tahoe.commands.RunWithClonedSparkSession.runWithClonedSparkSession(DMLUtils.scala:128)\n\tat com.databricks.sql.transaction.tahoe.commands.RunWithClonedSparkSession.runWithClonedSparkSession$(DMLUtils.scala:121)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.runWithClonedSparkSession(DeltaDMLCommandEdge.scala:55)\n\tat com.databricks.sql.transaction.tahoe.commands.DeltaDMLCommandEdge.run(DeltaDMLCommandEdge.scala:91)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:84)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:194)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:84)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:81)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:94)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:432)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:432)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:431)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:477)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:413)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:343)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:209)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:700)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:427)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1268)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:423)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:360)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:421)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:485)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:480)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:480)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:480)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:316)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1755)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1816)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:321)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:406)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$3(Dataset.scala:150)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1454)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1454)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:141)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1127)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1447)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1079)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1151)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:448)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:472)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:467)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1287)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1278)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:128)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1203)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1687)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:846)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:1046)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:1035)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:1081)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:81)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:1081)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:758)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:851)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:622)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:81)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:617)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:540)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:371)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\n\t\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException(DeltaErrors.scala:2675)\n\t\tat com.databricks.sql.transaction.tahoe.DeltaErrorsBase.concurrentAppendException$(DeltaErrors.scala:2668)\n\t\tat com.databricks.sql.transaction.tahoe.DeltaErrors$.concurrentAppendException(DeltaErrors.scala:3948)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$3(ConflictCheckerEdge.scala:626)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.$anonfun$checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn$1(ConflictCheckerEdge.scala:651)\n\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictChecker.recordTime(ConflictChecker.scala:1247)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkForAddedFilesThatShouldHaveBeenReadByCurrentTxn(ConflictCheckerEdge.scala:587)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictChecker.checkConflicts(ConflictChecker.scala:471)\n\t\tat com.databricks.sql.transaction.tahoe.ConflictCheckerEdge.checkConflicts(ConflictCheckerEdge.scala:252)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion(OptimisticTransactionImplEdge.scala:1069)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImplEdge.checkForConflictsAgainstVersion$(OptimisticTransactionImplEdge.scala:1051)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflictsAgainstVersion(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10(OptimisticTransaction.scala:3181)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$10$adapted(OptimisticTransaction.scala:3177)\n\t\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\t\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\t\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\t\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\t\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\t\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$2(OptimisticTransaction.scala:3177)\n\t\tat com.databricks.sql.transaction.tahoe.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:697)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$checkForConflicts$1(OptimisticTransaction.scala:3136)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\t\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\t\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\t\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\t\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\t\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\t\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\t\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\t\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\t\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\t\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:171)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:161)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:150)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts(OptimisticTransaction.scala:3136)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.checkForConflicts$(OptimisticTransaction.scala:3126)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.checkForConflicts(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransactionImpl.$anonfun$doCommitRetryIteratively$4(OptimisticTransaction.scala:2659)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:248)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:235)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:173)\n\t\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:317)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:315)\n\t\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:196)\n\t\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:172)\n\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\t\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\t\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\t\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\t\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\t\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\t\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\t\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\t\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\t\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\t\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:30)\n\t\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:120)\n\t\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:210)\n\t\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\t\tat com.databricks.spark"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "UPDATE student_serializable SET favorite_color=\"violet\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b4aed6d-966c-4f75-9b49-2a019bacab9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
